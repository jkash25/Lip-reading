{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2\n",
    "import imageio\n",
    "from PIL import Image\n",
    "from imutils import face_utils\n",
    "import time\n",
    "from keras.utils import np_utils, generic_utils\n",
    "import shutil\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skimage.transform import resize\n",
    "from sklearn.utils import shuffle\n",
    "from skimage.io import imread, imsave, imshow\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Activation, GlobalAveragePooling2D,GlobalMaxPool2D,ZeroPadding3D, Bidirectional,TimeDistributed, LSTM, GRU, Reshape,BatchNormalization, ConvLSTM2D, ConvLSTM3D,Input\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "# from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'LipNet'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/rizkiarm/LipNet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "words = ['Begin','Choose','Connection','Navigation','Next', 'Previous', 'Start','Stop','Hello','Web']\n",
    "phrases = [\"Stop navigaton\",\"Excuse me\",\"I am sorry\",\"Thank you\",'Good bye','I love this game','Nice to meet you','You are welcome','How are you?','Have a good time']\n",
    "phrases_di = {i:phrases[i] for i in range(len(phrases))}\n",
    "\n",
    "\n",
    "words_di = {i:words[i] for i in range(len(words))}\n",
    "unseen_test = ['F04']\n",
    "unseen_validation = ['F07','M02']\n",
    "starting_path = 'C:\\\\Users\\\\Jai K\\\\CS Stuff\\\\Python\\\\ISR Project\\\\dataset\\\\dataset'\n",
    "people = ['F01','F02','F04','F05','F06','F07','F08','F09','F10','F11','M01','M02','M04','M07','M08']\n",
    "#people = ['F01']\n",
    "data_types = ['words']\n",
    "folder_nums = ['01','02','03','04','05','06','07','08','09','10']\n",
    "instances = ['01','02','03','04','05','06','07','08','09','10']\n",
    "image_nums = ['color_001','color_002','color_003','color_004','color_005','color_006','color_007','color008','color_009','color_010']#,'color_11','color_12','color_13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Begin', 1: 'Choose', 2: 'Connection', 3: 'Navigation', 4: 'Next', 5: 'Previous', 6: 'Start', 7: 'Stop', 8: 'Hello', 9: 'Web'}\n"
     ]
    }
   ],
   "source": [
    "print(words_di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_save():\n",
    "    MAX_HEIGHT = 100\n",
    "    MAX_WIDTH = 100\n",
    "    max_seq_length = 10\n",
    "    t1 = time.time()\n",
    "    hog_face_detector = dlib.get_frontal_face_detector()\n",
    "    dlib_facelandmark = dlib.shape_predictor('C:\\\\Users\\\\Jai K\\\\CS Stuff\\\\Python\\\\ISR Project\\\\shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "    for person in people:\n",
    "        tx1 = time.time()\n",
    "        for data_type in data_types:\n",
    "            for word_index,folder in enumerate(tqdm(folder_nums)):\n",
    "                for instance in instances:\n",
    "                    sequence = []\n",
    "                    #sequence = np.array(sequence)\n",
    "                    for image in image_nums:\n",
    "                        path = starting_path + '\\\\' + person + '\\\\' + data_type + '\\\\' + folder + '\\\\'+instance + '\\\\' + image + '.jpg'\n",
    "                        \n",
    "\n",
    "                        if(os.path.exists(path) and path.__contains__('color')):\n",
    "                            frame = cv2.imread(path)\n",
    "                            \n",
    "                            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                            x_arr = []\n",
    "                            y_arr = []\n",
    "                            gray = imutils.resize(gray, width=500)\n",
    "                            copy = gray.copy()\n",
    "                            faces = hog_face_detector(gray)\n",
    "                            for face in faces:\n",
    "\n",
    "                                face_landmarks = dlib_facelandmark(gray, face)\n",
    "\n",
    "                                for n in range(48, 68):\n",
    "                                    x = face_landmarks.part(n).x\n",
    "                                    y = face_landmarks.part(n).y\n",
    "                                    x_arr.append(x)\n",
    "                                    y_arr.append(y)\n",
    "                                    #print(face_landmarks.part(n))\n",
    "\n",
    "                                    xmax = max(x_arr)\n",
    "                                    xmin = min(x_arr)\n",
    "                                    ymax = max(y_arr)\n",
    "                                    ymin = min(y_arr)\n",
    "\n",
    "                                    cv2.circle(gray, (x, y), 1, (0, 255, 255), 1)\n",
    "                            copy = copy[ymin-1:ymax+3, xmin-5:xmax+5]\n",
    "                            width2 = 100\n",
    "                            height2 = 100\n",
    "                            dim = (width2, height2)\n",
    "                            resized_cropped = cv2.resize(copy, dim, interpolation = cv2.INTER_AREA)\n",
    "                            MAX_WIDTH, MAX_HEIGHT = resized_cropped.shape\n",
    "                            max_seq_length = 10\n",
    "                            resized_cropped = resized_cropped.astype(np.uint8)\n",
    "                            sequence.append(resized_cropped)\n",
    "                        else:\n",
    "                            continue\n",
    "                    pad_array = [np.zeros((MAX_WIDTH, MAX_HEIGHT))]           \n",
    "                    sequence.extend(pad_array * (max_seq_length - len(sequence)))\n",
    "                    sequence = np.array(sequence)\n",
    "                    if person in unseen_test:\n",
    "                        x_test.append(sequence)\n",
    "                        y_test.append(word_index)\n",
    "                    elif person in unseen_validation:\n",
    "                        x_val.append(sequence)\n",
    "                        y_val.append(word_index)\n",
    "                    else:\n",
    "                        x_train.append(sequence)\n",
    "                        y_train.append(word_index)\n",
    "        tx2 = time.time()\n",
    "        print(f'Finished reading images for person {person}. Time taken : {tx2 - tx1} secs.')\n",
    "    t2 = time.time()\n",
    "    print(f\"Time taken to create 3D Tensor from cropped lip images: {t2 - t1} secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading images for person F01. Time taken : 14.838965654373169 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:15<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading images for person F02. Time taken : 15.49447751045227 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:21<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading images for person F04. Time taken : 21.688720703125 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading images for person F05. Time taken : 17.238247871398926 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:24<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading images for person F06. Time taken : 24.368489503860474 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:26<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading images for person F07. Time taken : 26.756532192230225 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:16<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading images for person F08. Time taken : 16.17273712158203 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading images for person F09. Time taken : 17.35946822166443 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:15<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading images for person F10. Time taken : 15.599406719207764 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:15<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading images for person F11. Time taken : 15.285808324813843 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:16<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading images for person M01. Time taken : 16.26610517501831 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading images for person M02. Time taken : 17.318353176116943 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading images for person M04. Time taken : 17.377177238464355 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:16<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading images for person M07. Time taken : 16.043601512908936 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading images for person M08. Time taken : 14.633288621902466 secs.\n",
      "Time taken to create 3D Tensor from cropped lip images: 267.35346245765686 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "crop_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Training shape:  (1200, 10, 100, 100)\n",
      "X Test shape:  (100, 10, 100, 100)\n",
      "X Validation shape:  (200, 10, 100, 100)\n",
      "Y Training shape:  (1200,)\n",
      "Y Test shape:  (100,)\n",
      "Y Validation shape:  (200,)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "x_val = np.array(x_val)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# x_val = x_train[:10,:]\n",
    "# x_test= x_train[10:20,:]\n",
    "# x_train = x_train[20:,:]\n",
    "# y_val = y_train[:10]\n",
    "# y_test= y_train[10:20]\n",
    "# y_train = y_train[20:]\n",
    "\n",
    "\n",
    "print(\"X Training shape: \",x_train.shape)\n",
    "print(\"X Test shape: \",x_test.shape)\n",
    "print(\"X Validation shape: \",x_val.shape)\n",
    "print(\"Y Training shape: \",y_train.shape)\n",
    "print(\"Y Test shape: \",y_test.shape)\n",
    "print(\"Y Validation shape: \",y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "x =np.isnan(x_val).sum()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_it(X):\n",
    "    # print(np.isnan(X).sum())\n",
    "    # mean = np.mean(X,axis=(2,3),keepdims=True)\n",
    "\n",
    "    # std = np.std(X,axis=(2,3),  keepdims=True)\n",
    "    # print((std==0).sum())\n",
    "    # X = (X - mean)/std\n",
    "    # print(np.isnan(X).sum())\n",
    "    v_min = X.min(axis=(2, 3), keepdims=True)\n",
    "    v_max = X.max(axis=(2, 3), keepdims=True)\n",
    "    #print(v_min)\n",
    "    #print('Max: ',v_max)\n",
    "    X = (X - v_min)/(v_max - v_min)\n",
    "    X = np.nan_to_num(X)\n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(x_train,x_val,x_test,y_train,y_val,y_test):\n",
    "    print()\n",
    "    print(\"Normalizing data...\")\n",
    "    t1 = time.time()\n",
    "    x_train = normalize_it(x_train)\n",
    "    #print(X_train)\n",
    "    x_val = normalize_it(x_val)\n",
    "    x_test = normalize_it(x_test)\n",
    "    t2 =time.time()\n",
    "    print()\n",
    "    print(f\"Time taken to normalize images: {t2 - t1} secs\")\n",
    "\n",
    "    print()\n",
    "    print(\"One hot encoding labels...\")\n",
    "    t3 = time.time()\n",
    "    y_train = np_utils.to_categorical(y_train, 10)\n",
    "    y_test = np_utils.to_categorical(y_test, 10)\n",
    "    y_val = np_utils.to_categorical(y_val, 10)\n",
    "    t4 = time.time()\n",
    "    print()\n",
    "    print(f\"Time taken to convert labels to categorical: {t4 - t3} secs\")\n",
    "\n",
    "    print()\n",
    "    print(\"Shuffling data...\")\n",
    "    t5 = time.time()\n",
    "    X_train, y_train = shuffle(x_train, y_train, random_state=0)\n",
    "    X_test, y_test = shuffle(x_test, y_test, random_state=0)\n",
    "    X_val, y_val = shuffle(x_val, y_val, random_state=0)\n",
    "    t6 = time.time()\n",
    "    print()\n",
    "    print(f\"Time taken to shuffle data: {t6 - t5} secs\")\n",
    "    \n",
    "    print()\n",
    "    print(\"Reshaping data...\")\n",
    "    t7 = time.time()\n",
    "    x_train = np.expand_dims(x_train, axis=4)\n",
    "    x_val = np.expand_dims(x_val, axis=4)\n",
    "    x_test = np.expand_dims(x_test, axis=4)\n",
    "    t8 = time.time()\n",
    "    print()\n",
    "    print(f\"Time taken to reshape data: {t8 - t7} secs\")\n",
    "    print()\n",
    "\n",
    "    print(x_train.shape)\n",
    "    print(x_val.shape)\n",
    "    print(x_test.shape)\n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing data...\n",
      "\n",
      "Time taken to normalize images: 2.2171103954315186 secs\n",
      "\n",
      "One hot encoding labels...\n",
      "\n",
      "Time taken to convert labels to categorical: 0.005981922149658203 secs\n",
      "\n",
      "Shuffling data...\n",
      "\n",
      "Time taken to shuffle data: 0.3474314212799072 secs\n",
      "\n",
      "Reshaping data...\n",
      "\n",
      "Time taken to reshape data: 0.0 secs\n",
      "\n",
      "(1200, 10, 100, 100, 1)\n",
      "(200, 10, 100, 100, 1)\n",
      "(100, 10, 100, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, x_test, y_train, y_val, y_test = clean(x_train,x_val,x_test,y_train,y_val,y_test)\n",
    "\n",
    "np.save('x_train',x_train)\n",
    "np.save('x_val',x_val)\n",
    "np.save('x_test',x_test)\n",
    "np.save('y_train',y_train)\n",
    "np.save('y_val',y_val)\n",
    "np.save('y_test',y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 8 0 5 7 9 1 7 5 9 5 9 7 1 0 3 2 2 3 0 4 6 0 7 4 4 0 9 8 7 6 8 9 6 5 2 1\n",
      " 5 6 7 0 6 4 4 0 1 1 4 3 0 9 5 0 3 2 5 1 3 2 5 1 3 6 5 7 8 3 8 1 8 1 2 4 9\n",
      " 9 6 2 9 7 7 2 3 8 4 3 6 5 1 8 7 8 3 2 8 0 9 6 6 4 4]\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(y_test, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 10)\n",
      "(30, 10)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "\n",
    "y_train30 = y_train[:30,:]\n",
    "x_train30 = x_train[:30,:]\n",
    "x_test30 = x_test[:30,:]\n",
    "y_test30 = y_test[:30,:]\n",
    "x_val30 = x_val[:30,:]\n",
    "y_val30 = y_val[:30,:]\n",
    "print(y_train30.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Training shape:  (1200, 10, 100, 100, 1)\n",
      "X Test shape:  (100, 10, 100, 100, 1)\n",
      "X Validation shape:  (200, 10, 100, 100, 1)\n",
      "Y Training shape:  (1200, 10)\n",
      "Y Test shape:  (100, 10)\n",
      "Y Validation shape:  (200, 10)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.load('x_train.npy')\n",
    "x_test = np.load('x_test.npy')\n",
    "x_val = np.load('x_val.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "y_test = np.load('y_test.npy')\n",
    "y_val = np.load('y_val.npy')\n",
    "\n",
    "print(\"X Training shape: \",x_train.shape)\n",
    "print(\"X Test shape: \",x_test.shape)\n",
    "print(\"X Validation shape: \",x_val.shape)\n",
    "print(\"Y Training shape: \",y_train.shape)\n",
    "print(\"Y Test shape: \",y_test.shape)\n",
    "print(\"Y Validation shape: \",y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"conv3d_2\" (type Conv3D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node conv3d_2/Conv3D}} = Conv3D[T=DT_FLOAT, data_format=\"NDHWC\", dilations=[1, 1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1, 1]](Placeholder, conv3d_2/Conv3D/ReadVariableOp)' with input shapes: [?,1,23,23,128], [2,2,2,128,256].\n\nCall arguments received by layer \"conv3d_2\" (type Conv3D):\n  • inputs=tf.Tensor(shape=(None, 1, 23, 23, 128), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m model\u001b[39m.\u001b[39madd(Conv3D(\u001b[39m128\u001b[39m, (\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m), activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, strides\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m      9\u001b[0m model\u001b[39m.\u001b[39madd(MaxPooling3D(pool_size\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m), strides\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m))\n\u001b[1;32m---> 11\u001b[0m model\u001b[39m.\u001b[39;49madd(Conv3D(\u001b[39m256\u001b[39;49m, (\u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m), activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, strides\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[0;32m     12\u001b[0m model\u001b[39m.\u001b[39madd(MaxPooling3D(pool_size\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m), strides\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m))\n\u001b[0;32m     14\u001b[0m \u001b[39m#model.add(Conv3D(512,(3,3,3),activation='relu',strides=1))\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m#model.add(MaxPooling3D(pool_size=(2,2,2),strides=2))\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jai K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jai K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Jai K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1967\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1964\u001b[0m   c_op \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39mTF_FinishOperation(op_desc)\n\u001b[0;32m   1965\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1966\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[1;32m-> 1967\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(e\u001b[39m.\u001b[39mmessage)\n\u001b[0;32m   1969\u001b[0m \u001b[39m# Record the current Python stack trace as the creating stacktrace of this\u001b[39;00m\n\u001b[0;32m   1970\u001b[0m \u001b[39m# TF_Operation.\u001b[39;00m\n\u001b[0;32m   1971\u001b[0m \u001b[39mif\u001b[39;00m extract_traceback:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"conv3d_2\" (type Conv3D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node conv3d_2/Conv3D}} = Conv3D[T=DT_FLOAT, data_format=\"NDHWC\", dilations=[1, 1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1, 1]](Placeholder, conv3d_2/Conv3D/ReadVariableOp)' with input shapes: [?,1,23,23,128], [2,2,2,128,256].\n\nCall arguments received by layer \"conv3d_2\" (type Conv3D):\n  • inputs=tf.Tensor(shape=(None, 1, 23, 23, 128), dtype=float32)"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# # 1st layer group\n",
    "model.add(Conv3D(64, (3, 3, 3), strides = 1, input_shape=(13, 100, 100, 1), activation='relu', padding='valid'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
    "\n",
    "model.add(Conv3D(128, (3, 3, 3), activation='relu', strides=1))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
    "\n",
    "model.add(Conv3D(256, (2, 2, 2), activation='relu', strides=1))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
    "\n",
    "#model.add(Conv3D(512,(3,3,3),activation='relu',strides=1))\n",
    "#model.add(MaxPooling3D(pool_size=(2,2,2),strides=2))\n",
    "model.add((Flatten()))\n",
    "\n",
    "# # # FC layers group\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_4 (Conv3D)           (None, 8, 98, 98, 32)     896       \n",
      "                                                                 \n",
      " max_pooling3d_3 (MaxPooling  (None, 4, 49, 49, 32)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_5 (Conv3D)           (None, 4, 49, 49, 64)     55360     \n",
      "                                                                 \n",
      " max_pooling3d_4 (MaxPooling  (None, 2, 24, 24, 64)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_6 (Conv3D)           (None, 2, 24, 24, 128)    221312    \n",
      "                                                                 \n",
      " max_pooling3d_5 (MaxPooling  (None, 1, 12, 12, 128)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 18432)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                184330    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 461,898\n",
      "Trainable params: 461,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "earlyStopping = EarlyStopping(monitor = 'accuracy', patience = 10)\n",
    "model = Sequential()\n",
    "#change activation functions - sigmoid, etc\n",
    "#change strides\n",
    "# 1st layer group\n",
    "model.add(Conv3D(32, (3, 3, 3), strides = 1, input_shape=(10, 100, 100, 1), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
    "\n",
    "model.add(Conv3D(64, (3, 3, 3), activation='relu', strides=1,padding='same'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv3D(128, (3, 3, 3), activation='relu', strides=1,padding='same'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
    "\n",
    "#model.add(Conv3D(256,(3,3,3),activation='relu',strides=1))\n",
    "#model.add(MaxPooling3D(pool_size=(2,2,2),strides=2))\n",
    "#model.add(Dropout(0.5))\n",
    "#print(model.summary())\n",
    "#model.add(Conv3D(256, (3, 3, 3), activation='relu', strides=1))\n",
    "#model.add(MaxPooling3D(pool_size=(2,2,2),strides=2))\n",
    "\n",
    "#model.add(Conv3D(128, (3, 3, 3), activation='relu', strides=1))\n",
    "\n",
    "shape = (1,10,10,128)\n",
    "#model.add(Reshape((1,shape[1]*shape[2]*shape[3])))\n",
    "model.add((Flatten()))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = 'Adam',metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"lstm1\" is incompatible with the layer: expected ndim=3, found ndim=5. Full shape received: (None, 10, 49, 49, 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m model\u001b[39m.\u001b[39madd(Conv3D(\u001b[39m64\u001b[39m, kernel_size\u001b[39m=\u001b[39m(\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m), activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m,name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconv1\u001b[39m\u001b[39m'\u001b[39m,strides\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m),input_shape\u001b[39m=\u001b[39m(\u001b[39m13\u001b[39m,\u001b[39m100\u001b[39m,\u001b[39m100\u001b[39m,\u001b[39m1\u001b[39m)))\n\u001b[0;32m      7\u001b[0m model\u001b[39m.\u001b[39madd(MaxPooling3D(pool_size\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m), strides\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m2\u001b[39m),padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m'\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpool1\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m----> 8\u001b[0m model\u001b[39m.\u001b[39;49madd(LSTM(\u001b[39m64\u001b[39;49m, return_sequences\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlstm1\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m      9\u001b[0m \u001b[39m# 2nd layer group\u001b[39;00m\n\u001b[0;32m     11\u001b[0m model\u001b[39m.\u001b[39madd(Conv3D(\u001b[39m128\u001b[39m, kernel_size\u001b[39m=\u001b[39m(\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m), activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m,padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconv2\u001b[39m\u001b[39m'\u001b[39m,strides\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)))\n",
      "File \u001b[1;32mc:\\Users\\Jai K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jai K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Jai K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py:232\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    230\u001b[0m     ndim \u001b[39m=\u001b[39m shape\u001b[39m.\u001b[39mrank\n\u001b[0;32m    231\u001b[0m     \u001b[39mif\u001b[39;00m ndim \u001b[39m!=\u001b[39m spec\u001b[39m.\u001b[39mndim:\n\u001b[1;32m--> 232\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    233\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    234\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mis incompatible with the layer: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    235\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpected ndim=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mndim\u001b[39m}\u001b[39;00m\u001b[39m, found ndim=\u001b[39m\u001b[39m{\u001b[39;00mndim\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    236\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFull shape received: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(shape)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    237\u001b[0m         )\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mmax_ndim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"lstm1\" is incompatible with the layer: expected ndim=3, found ndim=5. Full shape received: (None, 10, 49, 49, 64)"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# 1st layer group\n",
    "\n",
    "model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu',name='conv1',strides=(1, 1, 1),input_shape=(13,100,100,1)))\n",
    "\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(1,2,2),padding='valid', name='pool1'))\n",
    "model.add(LSTM(64, return_sequences=True, name='lstm1'))\n",
    "# 2nd layer group\n",
    "\n",
    "model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu',padding='same', name='conv2',strides=(1, 1, 1)))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),padding='valid', name='pool2'))\n",
    "model.add(LSTM(128, return_sequences=True, name='lstm2'))\n",
    "# 3rd layer group\n",
    "\n",
    "model.add(Conv3D(256, kernel_size=(3, 3, 3), activation='relu',padding='same', name='conv3a',strides=(1, 1, 1)))\n",
    "model.add(Conv3D(256, kernel_size=(3, 3, 3), activation='relu',padding='same', name='conv3b',strides=(1, 1, 1)))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),padding='valid', name='pool3'))\n",
    "model.add(LSTM(256, return_sequences=True, name='lstm3'))\n",
    "# 4th layer group\n",
    "model.add(Dense(4096, activation='relu', name='fc6'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu', name='fc7'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# model.add(Conv3D(512, kernel_size=(3, 3, 3), activation='relu',padding='same', name='conv4a',strides=(1, 1, 1)))\n",
    "# model.add(Conv3D(512, kernel_size=(3, 3, 3), activation='relu',padding='same', name='conv4b',strides=(1, 1, 1)))\n",
    "# print(model.summary())\n",
    "\n",
    "# model.add(MaxPooling3D( strides=(2, 2, 2),padding='valid', name='pool4'))\n",
    "\n",
    "# # 5th layer group\n",
    "\n",
    "# model.add(Conv3D(512, kernel_size=(3, 3, 3), activation='relu',padding='same', name='conv5a',strides=(1, 1, 1)))\n",
    "# model.add(Conv3D(512, kernel_size=(3, 3, 3), activation='relu',padding='same', name='conv5b',strides=(1, 1, 1)))\n",
    "# model.add(ZeroPadding3D(padding=(0, 1, 1)))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),padding='valid', name='pool5'))\n",
    "# model.add(Flatten())\n",
    "# # FC layers group\n",
    "# model.add(Dense(4096, activation='relu', name='fc6'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(4096, activation='relu', name='fc7'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_11 (Conv3D)          (None, 10, 50, 50, 25)    700       \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 10, 10, 5, 50, 25  0         \n",
      "                             )                                   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 10, 8, 3, 48, 256  4231168  \n",
      " l)                          )                                   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 10, 6, 1, 46, 256  10617856 \n",
      " nal)                        )                                   \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 706560)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                7065610   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,915,334\n",
      "Trainable params: 21,915,334\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "earlyStopping = EarlyStopping(monitor='accuracy', patience=10)\n",
    "model = Sequential()\n",
    "model.add((Conv3D(25,strides=(1,2,2),kernel_size=(3,3,3),padding='same',input_shape=(10,100,100,1))))\n",
    "\n",
    "model.add(Reshape((10,10,5,50,25)))\n",
    "#model.add(Reshape((10,62500)))\n",
    "\n",
    "model.add(Bidirectional(ConvLSTM3D(128,kernel_size=(3,3,3),return_sequences=True)))\n",
    "model.add(Bidirectional(ConvLSTM3D(128,kernel_size=(3,3,3),return_sequences=True)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "print(model.summary())  \n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_7 (Conv3D)           (None, 10, 100, 100, 64)  128       \n",
      "                                                                 \n",
      " max_pooling3d_5 (MaxPooling  (None, 5, 50, 50, 64)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_8 (Conv3D)           (None, 5, 50, 50, 128)    8320      \n",
      "                                                                 \n",
      " max_pooling3d_6 (MaxPooling  (None, 2, 25, 25, 128)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_9 (Conv3D)           (None, 2, 25, 25, 256)    33024     \n",
      "                                                                 \n",
      " max_pooling3d_7 (MaxPooling  (None, 1, 12, 12, 256)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_10 (Conv3D)          (None, 1, 12, 12, 512)    131584    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 73728)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                737290    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 910,346\n",
      "Trainable params: 910,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv3D(64,kernel_size=1,activation='relu',input_shape=(10,100,100,1)))\n",
    "model.add(MaxPooling3D(strides=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(128,kernel_size=1,activation='relu'))\n",
    "model.add(MaxPooling3D(strides=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(256,kernel_size=1,activation='relu'))\n",
    "model.add(MaxPooling3D(strides=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(512,kernel_size=1,activation='relu'))\n",
    "#model.add(MaxPooling3D(strides=(2,2,2)))\n",
    "\n",
    "#model.add(Conv3D(1024,kernel_size=1,activation='relu'))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " zero1 (ZeroPadding3D)       (None, 12, 104, 104, 1)   0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " zero1 (ZeroPadding3D)       (None, 12, 104, 104, 1)   0         \n",
      "                                                                 \n",
      " conv1 (Conv3D)              (None, 10, 50, 50, 32)    2432      \n",
      "                                                                 \n",
      " max1 (MaxPooling3D)         (None, 10, 25, 25, 32)    0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 10, 25, 25, 32)    0         \n",
      "                                                                 \n",
      " zero2 (ZeroPadding3D)       (None, 12, 29, 29, 32)    0         \n",
      "                                                                 \n",
      " conv2 (Conv3D)              (None, 10, 25, 25, 64)    153664    \n",
      "                                                                 \n",
      " max2 (MaxPooling3D)         (None, 10, 12, 12, 64)    0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 10, 12, 12, 64)    0         \n",
      "                                                                 \n",
      " zero3 (ZeroPadding3D)       (None, 12, 14, 14, 64)    0         \n",
      "                                                                 \n",
      " conv3 (Conv3D)              (None, 10, 12, 12, 96)    165984    \n",
      "                                                                 \n",
      " max3 (MaxPooling3D)         (None, 10, 6, 6, 96)      0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 10, 6, 6, 96)      0         \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 10, 3456)         0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 10, 512)          5704704   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 10, 512)          1182720   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 5120)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                51210     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,260,714\n",
      "Trainable params: 7,260,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# import lipnet\n",
    "# from lipnet.core.layers import CTC\n",
    "input_shape = (10,100,100,1)\n",
    "model = Sequential()\n",
    "model.add(Input(name='input',shape=input_shape,dtype='float32'))\n",
    "model.add(ZeroPadding3D(padding=(1, 2, 2), name='zero1'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.add((Conv3D(32, (3, 5, 5), strides=(1, 2, 2), activation='relu', kernel_initializer='he_normal', name='conv1')))\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max1'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(ZeroPadding3D(padding=(1, 2, 2), name='zero2'))\n",
    "model.add(Conv3D(64, (3, 5, 5), strides=(1, 1, 1), activation='relu', kernel_initializer='he_normal', name='conv2'))\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max2'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(ZeroPadding3D(padding=(1, 1, 1), name='zero3'))\n",
    "model.add(Conv3D(96, (3, 3, 3), strides=(1, 1, 1), activation='relu', kernel_initializer='he_normal', name='conv3'))\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max3'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Bidirectional(GRU(256, return_sequences=True, kernel_initializer='Orthogonal', name='gru1'), merge_mode='concat'))\n",
    "model.add(Bidirectional(GRU(256, return_sequences=True, kernel_initializer='Orthogonal', name='gru2'), merge_mode='concat'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train30' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(x_train30)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train30' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(y_train).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "38/38 [==============================] - 160s 4s/step - loss: 2.7987 - accuracy: 0.1192 - val_loss: 2.5321 - val_accuracy: 0.1000\n",
      "Epoch 2/45\n",
      "38/38 [==============================] - 165s 4s/step - loss: 2.3884 - accuracy: 0.0933 - val_loss: 2.3248 - val_accuracy: 0.1000\n",
      "Epoch 3/45\n",
      "38/38 [==============================] - 184s 5s/step - loss: 2.3591 - accuracy: 0.0950 - val_loss: 2.3238 - val_accuracy: 0.0950\n",
      "Epoch 4/45\n",
      "38/38 [==============================] - 184s 5s/step - loss: 2.3284 - accuracy: 0.1000 - val_loss: 2.3223 - val_accuracy: 0.1000\n",
      "Epoch 5/45\n",
      "12/38 [========>.....................] - ETA: 1:53 - loss: 2.3143 - accuracy: 0.0964"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m t1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m      2\u001b[0m \u001b[39m#history = model.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks = [earlyStopping], epochs=45)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, validation_data\u001b[39m=\u001b[39;49m(x_val, y_val), epochs\u001b[39m=\u001b[39;49m\u001b[39m45\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m t2 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Jai K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Jai K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Jai K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Jai K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Jai K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Jai K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Jai K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Jai K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Jai K\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "#history = model.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks = [earlyStopping], epochs=45)\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=45)\n",
    "t2 = time.time()\n",
    "print()\n",
    "print(f\"Training time : {(t2 - t1)/60} mins.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlim(1, 40)\n",
    "# plt.ylim(0, 3)\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 892ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = model.predict(x_test)\n",
    "\n",
    "# predicted_words = [words[i] for i in np.argmax(ypred, axis=1)]\n",
    "# actual_words = [words[i] for i in np.argmax(y_test,axis=1)]\n",
    "predicted_words = [phrases[i] for i in np.argmax(ypred, axis=1)]\n",
    "actual_words = [phrases[i] for i in np.argmax(y_test,axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted : Stop navigaton \t Actual : Excuse me\n",
      "Predicted : Stop navigaton \t Actual : Excuse me\n",
      "Predicted : Stop navigaton \t Actual : Excuse me\n",
      "Predicted : Stop navigaton \t Actual : Excuse me\n",
      "Predicted : Stop navigaton \t Actual : Excuse me\n",
      "Predicted : Stop navigaton \t Actual : Excuse me\n",
      "Predicted : Stop navigaton \t Actual : Excuse me\n",
      "Predicted : Stop navigaton \t Actual : Excuse me\n",
      "Predicted : Stop navigaton \t Actual : Excuse me\n",
      "Predicted : Stop navigaton \t Actual : Excuse me\n",
      "\n",
      "\n",
      "Accuracy = 0.0% on training data\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for p, a in zip(predicted_words, actual_words):\n",
    "    if p == a:\n",
    "        correct += 1\n",
    "    print(f\"Predicted : {p} \\t Actual : {a}\")\n",
    "\n",
    "accuracy = correct/len(actual_words)\n",
    "print()\n",
    "print()\n",
    "print(f\"Accuracy = {accuracy*100}% on training data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b1e5666bae04dd529d9cdc03df8eb25744c6e734a6948cf4306c9bfbc71bcf6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
